{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Homework 2\n",
    "\n",
    "In this homework, you will be implementing a neural network library in the needle framework. Reminder: __you must save a copy in drive__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Code to set up the assignment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Code to set up the assignment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "!mkdir -p 10714\n",
    "%cd /content/drive/MyDrive/10714\n",
    "!git clone https://github.com/dlsys10714/hw2.git\n",
    "%cd /content/drive/MyDrive/10714/hw2\n",
    "\n",
    "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_API_KEY = \"qTskW8hPqLZXWgkH0eHH\"\n",
    "HW2_NAME = \"hw2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0\n",
    "\n",
    "This homework builds off of Homework 1.\n",
    "\n",
    "**First, in your Homework 2 directory, copy the files `python/needle/autograd.py`, `python/needle/ops/ops_mathematic.py` from your Homework 1.**\n",
    "\n",
    "***NOTE***: The default data type for the tensor is `float32`. If you want to change the data type, you can do so by setting the `dtype` parameter in the `Tensor` constructor. For example, `Tensor([1, 2, 3], dtype='float64')` will create a tensor with `float64` data type. \n",
    "In this homework, **make sure any tensor you create has `float32` data type to avoid any issues with the autograder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1\n",
    "\n",
    "In this first question, you will implement a few different methods for weight initialization.  This will be done in the `python/needle/init/init_initializers.py` file, which contains a number of routines for initializing needle Tensors using various random and constant initializations.  Following the same methodology of the existing initializers (you will want to call e.g. `init.rand` or `init.randn` implemented in `python/needle/init/init_basic.py` from your functions below, implement the following common initialization methods.  In all cases, the functions should return `fan_in` by `fan_out` 2D tensors (extensions to other sizes can be done via e.g., reshaping).\n",
    "\n",
    "\n",
    "### Xavier uniform\n",
    "`xavier_uniform(fan_in, fan_out, gain=1.0, **kwargs)`\n",
    "\n",
    "Fills the input Tensor with values according to the method described in [Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), using a uniform distribution. The resulting Tensor will have values sampled from $\\mathcal{U}(-a, a)$ where \n",
    "\n",
    "$$a = \\text{gain} \\times \\sqrt{\\frac{6}{\\text{fan\\_in} + \\text{fan\\_out}}}$$\n",
    "\n",
    "Pass remaining `**kwargs` parameters to the corresponding `init` random call.\n",
    "\n",
    "##### Parameters\n",
    "- `fan_in` - dimensionality of input\n",
    "- `fan_out` - dimensionality of output\n",
    "- `gain` - optional scaling factor\n",
    "___\n",
    "\n",
    "### Xavier normal\n",
    "`xavier_normal(fan_in, fan_out, gain=1.0, **kwargs)`\n",
    "\n",
    "Fills the input Tensor with values according to the method described in [Understanding the difficulty of training deep feedforward neural networks](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), using a normal distribution. The resulting Tensor will have values sampled from $\\mathcal{N}(0, \\text{std}^2)$ where \n",
    "\n",
    "$$\\mathrm{std} = \\mathrm{gain} \\times \\sqrt{\\frac{2}{\\mathrm{fan}_{in} + \\mathrm{fan}_{out}}}$$\n",
    "\n",
    "##### Parameters\n",
    "- `fan_in` - dimensionality of input\n",
    "- `fan_out` - dimensionality of output\n",
    "- `gain` - optional scaling factor\n",
    "___\n",
    "\n",
    "### Kaiming uniform\n",
    "`kaiming_uniform(fan_in, fan_out, nonlinearity=\"relu\", **kwargs)`\n",
    "\n",
    "Fills the input Tensor with values according to the method described in [Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification](https://arxiv.org/pdf/1502.01852.pdf), using a uniform distribution. The resulting Tensor will have values sampled from $\\mathcal{U}(-\\text{bound}, \\text{bound})$ where \n",
    "\n",
    "$$\\mathrm{bound} = \\mathrm{gain} \\times \\sqrt{\\frac{3}{\\mathrm{fan}_{in}}}$$\n",
    "\n",
    "Use the recommended gain value for ReLU: $\\text{gain}=\\sqrt{2}$.\n",
    "\n",
    "##### Parameters\n",
    "- `fan_in` - dimensionality of input\n",
    "- `fan_out` - dimensionality of output\n",
    "- `nonlinearity` - the non-linear function\n",
    "___\n",
    "\n",
    "### Kaiming normal\n",
    "`kaiming_normal(fan_in, fan_out, nonlinearity=\"relu\", **kwargs)`\n",
    "\n",
    "Fills the input Tensor with values according to the method described in [Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification](https://arxiv.org/pdf/1502.01852.pdf), using a normal distribution. The resulted Tensor will have values sampled from $\\mathcal{N}(0, \\text{std}^2)$ where \n",
    "\n",
    "$$\\mathrm{std} = \\frac{\\mathrm{gain}}{\\sqrt{\\mathrm{fan}_{in}}}$$\n",
    "\n",
    "Use the recommended gain value for ReLU: $\\text{gain}=\\sqrt{2}$.\n",
    "\n",
    "##### Parameters\n",
    "- `fan_in` - dimensionality of input\n",
    "- `fan_out` - dimensionality of output\n",
    "- `nonlinearity` - the non-linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 89 deselected / 4 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_init_kaiming_uniform \u001b[32mPASSED\u001b[0m\u001b[32m         [ 25%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_init_kaiming_normal \u001b[32mPASSED\u001b[0m\u001b[32m          [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_init_xavier_uniform \u001b[32mPASSED\u001b[0m\u001b[32m          [ 75%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_init_xavier_normal \u001b[32mPASSED\u001b[0m\u001b[32m           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m4 passed\u001b[0m, \u001b[33m89 deselected\u001b[0m\u001b[32m in 0.29s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_init\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting init...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 2.09s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"init\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "In this question, you will implement additional modules in `python/needle/nn/nn_basic.py`. Specifically, for the following modules described below, initialize any variables of the module in the constructor, and fill out the `forward` method. **Note:** Be sure that you are using the `init` functions that you just implemented to initialize the parameters, and don't forget to pass the `dtype` argument.\n",
    "___\n",
    "\n",
    "### Linear\n",
    "`needle.nn.Linear(in_features, out_features, bias=True, device=None, dtype=\"float32\")`\n",
    "\n",
    "Applies a linear transformation to the incoming data: $y = xA^T + b$. The input shape is $(N, H_{\\text{in}})$ where $H_{\\text{in}}=\\text{in\\_features}$. The output shape is $(N, H_{\\text{out}})$ where $H_{\\text{out}}=\\text{out\\_features}$.\n",
    "\n",
    "**Be careful to explicitly broadcast the bias term to the correct shape -- Needle does not support implicit broadcasting.**\n",
    "\n",
    "**Note: for all layers including this one, you should initialize the weight Tensor before the bias Tensor, and should initialize all Parameters using only functions from `init`**. This initialization order requirement exists because the test case answers on mugrade were prepared assuming that weights are initialized before bias parameters. While initializing bias before weights would still be algorithmically correct, the model solutions and expected test outputs were generated using the weights-first convention. Therefore, to pass the automated tests on mugrade, you must follow this specific initialization order. If you encounter any ambiguity about which layer or parameter should be initialized first in other parts of this assignment, please raise a request on Ed for clarification. \n",
    "\n",
    "##### Parameters\n",
    "- `in_features` - size of each input sample\n",
    "- `out_features` - size of each output sample\n",
    "- `bias` - If set to `False`, the layer will not learn an additive bias.\n",
    "\n",
    "##### Variables\n",
    "- `weight` - the learnable weights of shape (`in_features`, `out_features`). The values should be **initialized with the Kaiming Uniform initialization** with `fan_in = in_features`\n",
    "- `bias` - the learnable bias of shape (`out_features`). The values should be initialized with the Kaiming Uniform initialization with `fan_in = out_features`. **Note the difference in fan_in choice, due to their relative sizes**. \n",
    "\n",
    "\n",
    "**NOTE:** Make sure to enclose all necessary variables e.g. (`weight`, `bias`) in the **`Parameter` class** so that they are visible to the optimizers which would be implemented next. **You can read `class Parameter` and the function `unpack_params` in `python/needle/nn/nn_basic.py` to understand more.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 85 deselected / 8 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_weight_init_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_bias_init_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_forward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_forward_2 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_forward_3 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_backward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_backward_2 [[ 24.5488      8.775347    4.387898  -21.248514   -3.9669373  24.256767\n",
      "    6.3171115   6.029777    0.8809935   3.5995162]\n",
      " [ 12.233745   -3.792646   -4.1903896  -5.106719  -12.004269   11.967942\n",
      "   11.939469   19.314493   10.631226   14.510731 ]\n",
      " [ 12.920014   -1.4545978  -3.0892954  -6.762379   -9.713004   12.523148\n",
      "    9.904757   15.442993    8.044141   11.4106865]]\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_linear_backward_3 [[[ 16.318823    0.3890714  -2.3196607 -10.607947   -8.891977\n",
      "    16.04581     9.475689   14.571134    6.581477   10.204643 ]\n",
      "  [ 20.291656    7.48733     1.2581345 -14.285493   -6.0252004\n",
      "    19.621624    4.343303    6.973201   -0.8103489   4.037069 ]\n",
      "  [ 11.332953   -5.698288   -8.815561   -7.673438   -7.6161675\n",
      "     9.361553   17.341637   17.269142   18.1076     14.261493 ]]]\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m8 passed\u001b[0m, \u001b[33m85 deselected\u001b[0m\u001b[32m in 0.25s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_linear\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_linear...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 1.14s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "`needle.nn.ReLU()`\n",
    "\n",
    "Applies the rectified linear unit function element-wise:\n",
    "$ReLU(x) = max(0, x)$.\n",
    "\n",
    "If you have previously implemented ReLU's backwards pass in terms of itself, note that this is numerically unstable and will likely cause problems\n",
    "down the line.\n",
    "Instead, consider that we could write the derivative of ReLU as $I\\{x>0\\}$, where, for this assignment, we arbitrarily decide and fix the convention that we will consider the derivative at $x=0$ to be 0.\n",
    "(This is a _subdifferentiable_ function.)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 91 deselected / 2 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_relu_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m            [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_relu_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m91 deselected\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_relu...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.43s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_relu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sequential\n",
    "`needle.nn.Sequential(*modules)`\n",
    "\n",
    "Applies a sequence of modules to the input (in the order that they were passed to the constructor) and returns the output of the last module.\n",
    "These should be kept in a `.module` property: you should _not_ redefine any magic methods like `__getitem__`, as this may not be compatible with our tests.\n",
    "\n",
    "##### Parameters\n",
    "- `*modules` - any number of modules of type `needle.nn.Module`\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 91 deselected / 2 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_sequential_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_sequential_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m     [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m91 deselected\u001b[0m\u001b[32m in 0.14s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_sequential\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_sequential...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.45s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LogSumExp\n",
    "\n",
    "`needle.ops.LogSumExp(axes)`\n",
    "\n",
    "Applies a numerically stable log-sum-exp function to the input by subtracting off the maximum elements. You will need to implement this and the next operation in file `python/needle/ops/ops_logarithmic.py`.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{LogSumExp}(z) = \\log (\\sum_{i} \\exp (z_i - \\max{z})) + \\max{z}\n",
    "\\end{equation}\n",
    "\n",
    "#### Parameters\n",
    "- `axes` - Tuple of axes to sum and take the maximum element over. This uses the same conventions as `needle.ops.Summation()`\n",
    "\n",
    "##### Why This Formulation? Handling Numerical Stability\n",
    "\n",
    "- **Naive definition:**  \n",
    "  The most direct way to define LogSumExp is  \n",
    "\n",
    "  $$\n",
    "  \\log \\left(\\sum_i \\exp(z_i)\\right)\n",
    "  $$\n",
    "\n",
    "- **The problem:**  \n",
    "  This naive computation is prone to numerical instability.  \n",
    "  - If some $z_i$ is very large (e.g. $1000$), then $\\exp(z_i)$ will overflow to $\\infty$.  \n",
    "  - If some $z_i$ is very small (e.g. $-1000$), then $\\exp(z_i)$ will underflow to $0$.  \n",
    "  Both cases can distort the result in floating-point arithmetic.  \n",
    "\n",
    "- **The fix:**  \n",
    "  To avoid this, we factor out the maximum element $M = \\max(z)$:  \n",
    "\n",
    "  $$\n",
    "  \\log \\left(\\sum_i \\exp(z_i)\\right)\n",
    "  = \\log \\left(\\exp(M)\\sum_i \\exp(z_i - M)\\right)\n",
    "  = M + \\log \\left(\\sum_i \\exp(z_i - M)\\right).\n",
    "  $$\n",
    "\n",
    "  Now all exponentials are at most $\\exp(0) = 1$, so overflow is completely avoided.  \n",
    "\n",
    "- **What about underflow?**  \n",
    "  Underflow can still occur if $z_i - M$ is very negative (e.g. $-1000$), since $\\exp(-1000) \\approx 0$ in floating-point.  \n",
    "  However, this is not a problem: such terms are already negligible compared to the maximum and do not meaningfully affect the sum.  \n",
    "\n",
    "\n",
    "The following blog post is also a good reference: https://indii.org/blog/gradients-of-softmax-and-logsumexp/\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 83 deselected / 10 selected                               \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_forward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_forward_2 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_forward_3 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_forward_4 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_forward_5 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_backward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_backward_2 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_backward_3 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_backward_5 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsumexp_backward_4 \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m83 deselected\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_op_logsumexp\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting op_logsumexp...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 1.41s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"op_logsumexp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogSoftmax\n",
    "\n",
    "`needle.ops.LogSoftmax(axes)`\n",
    "\n",
    "Applies a numerically stable logsoftmax function to the input by subtracting off the maximum elements.\n",
    "For this question, you can assume the input NDArray is 2 dimensional and we are doing softmax over `axis=1`.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{LogSoftmax}(z) = \\log \\left(\\frac{\\exp(z_i - \\max z)}{\\sum_{i}\\exp(z_i - \\max z)}\\right) = z - \\text{LogSumExp}(z)\n",
    "\\end{equation}\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 90 deselected / 3 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsoftmax_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m      [ 33%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsoftmax_stable_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_op_logsoftmax_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m     [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m3 passed\u001b[0m, \u001b[33m90 deselected\u001b[0m\u001b[32m in 0.26s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_op_logsoftmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting op_logsoftmax...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.76s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"op_logsoftmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SoftmaxLoss\n",
    "\n",
    "`needle.nn.SoftmaxLoss()` in `python/needle/nn/nn_basic.py`\n",
    "\n",
    "Applies the softmax loss as defined below (and as implemented in Homework 1), taking in as input a Tensor of logits and a Tensor of the true labels (expressed as a list of numbers, *not* one-hot encoded).\n",
    "\n",
    "Note that you can use the `init.one_hot` function now instead of writing this yourself.  Note: You will need to use the numerically stable logsumexp operator you just implemented for this purpose.\n",
    "\n",
    "\\begin{equation}\n",
    "\\ell_\\text{softmax}(z,y) = \\log \\sum_{i=1}^k \\exp z_i - z_y\n",
    "\\end{equation}\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 89 deselected / 4 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_softmax_loss_forward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_softmax_loss_forward_2 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_softmax_loss_backward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_softmax_loss_backward_2 \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m4 passed\u001b[0m, \u001b[33m89 deselected\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_softmax_loss\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_softmax_loss...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.78s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_softmax_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LayerNorm1d\n",
    "`needle.nn.LayerNorm1d(dim, eps=1e-5, device=None, dtype=\"float32\")`\n",
    "\n",
    "Applies layer normalization over a mini-batch of inputs as described in the paper [Layer Normalization](https://arxiv.org/abs/1607.06450).\n",
    "\n",
    "\\begin{equation}\n",
    "y = w \\circ \\frac{x_i - \\textbf{E}[x]}{((\\textbf{Var}[x]+\\epsilon)^{1/2})} + b\n",
    "\\end{equation}\n",
    "\n",
    "where $\\textbf{E}[x]$ denotes the empirical mean of the inputs, $\\textbf{Var}[x]$ denotes their empirical variance (note that here we are using the \"biased\" estimate of the variance, i.e., dividing by $N$ rather than by $N-1$), and $w$ and $b$ denote learnable scalar weights and biases respectively.  Note you can assume the input to this layer is a 2D tensor, with batches in the first dimension and features in the second. You might need to broadcast the weight and bias before applying them.\n",
    "\n",
    "##### Parameters\n",
    "- `dim` - number of channels\n",
    "- `eps` - a value added to the denominator for numerical stability.\n",
    "\n",
    "##### Variables\n",
    "- `weight` - the learnable weights of size `dim`, elements initialized to 1.\n",
    "- `bias` - the learnable bias of shape `dim`, elements initialized to 0.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 86 deselected / 7 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_forward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_forward_2 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_forward_3 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_backward_1 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_backward_2 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_backward_3 \u001b[32mPASSED\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_layernorm_backward_4 \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m7 passed\u001b[0m, \u001b[33m86 deselected\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_layernorm\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_layernorm...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 1.68s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_layernorm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Flatten\n",
    "`needle.nn.Flatten()`\n",
    "\n",
    "Takes in a tensor of shape `(B,X_0,X_1,...)`, and flattens all non-batch dimensions so that the output is of shape `(B, X_0 * X_1 * ...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 84 deselected / 9 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m         [ 11%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_forward_2 \u001b[32mPASSED\u001b[0m\u001b[32m         [ 22%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_forward_3 \u001b[32mPASSED\u001b[0m\u001b[32m         [ 33%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_forward_4 \u001b[32mPASSED\u001b[0m\u001b[32m         [ 44%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m        [ 55%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_backward_2 \u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_backward_3 \u001b[32mPASSED\u001b[0m\u001b[32m        [ 77%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_backward_4 \u001b[32mPASSED\u001b[0m\u001b[32m        [ 88%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_flatten_backward_5 \u001b[32mPASSED\u001b[0m\u001b[32m        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m9 passed\u001b[0m, \u001b[33m84 deselected\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_flatten\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_flatten...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 1.34s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_flatten\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm1d\n",
    "`needle.nn.BatchNorm1d(dim, eps=1e-5, momentum=0.1, device=None, dtype=\"float32\")`\n",
    "\n",
    "Applies batch normalization over a mini-batch of inputs as described in the paper [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167).\n",
    "\n",
    "\\begin{equation}\n",
    "y = w \\circ \\frac{z_i - \\textbf{E}[x]}{((\\textbf{Var}[x]+\\epsilon)^{1/2})} + b\n",
    "\\end{equation}\n",
    "\n",
    "but where here the mean and variance refer to the mean and variance over the _batch_dimensions.  The function also computes a running average of mean/variance for all features at each layer $\\hat{\\mu}, \\hat{\\sigma}^2$, and at test time normalizes by these quantities:\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\frac{(x - \\hat{mu})}{((\\hat{\\sigma}^2_{i+1})_j+\\epsilon)^{1/2}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "BatchNorm uses the running estimates of mean and variance instead of batch statistics at test time, i.e.,\n",
    "after `model.eval()` has been called on the BatchNorm layer's `training` flag is false.\n",
    "\n",
    "To compute the running estimates, you can use the equation $$\\hat{x_{new}} = (1 - m) \\hat{x_{old}} + mx_{observed},$$\n",
    "where $m$ is momentum.\n",
    "\n",
    "##### Parameters\n",
    "- `dim` - input dimension\n",
    "- `eps` - a value added to the denominator for numerical stability.\n",
    "- `momentum` - the value used for the running mean and running variance computation.\n",
    "\n",
    "##### Variables\n",
    "- `weight` - the learnable weights of size `dim`, elements initialized to 1.\n",
    "- `bias` - the learnable bias of size `dim`, elements initialized to 0.\n",
    "- `running_mean` - the running mean used at evaluation time, elements initialized to 0.\n",
    "- `running_var` - the running (unbiased) variance used at evaluation time, elements initialized to 1. \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 85 deselected / 8 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_check_model_eval_switches_training_flag_1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m       [ 25%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_forward_affine_1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_backward_affine_1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_running_mean_1 \u001b[32mPASSED\u001b[0m\u001b[32m  [ 75%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_running_var_1 \u001b[32mPASSED\u001b[0m\u001b[32m   [ 87%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_batchnorm_running_grad_1 \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m8 passed\u001b[0m, \u001b[33m85 deselected\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_batchnorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_batchnorm...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 1.34s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_batchnorm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "`needle.nn.Dropout(p = 0.5)`\n",
    "\n",
    "During training, randomly zeroes some of the elements of the input tensor with probability `p` using samples from a Bernoulli distribution. This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons as described in the paper [Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580). During evaluation the module simply computes an identity function. \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{z}_{i+1} = \\sigma_i (W_i^T z_i + b_i) \\\\\n",
    "(z_{i+1})_j = \n",
    "    \\begin{cases}\n",
    "    (\\hat{z}_{i+1})_j /(1-p) & \\text{with probability } 1-p \\\\\n",
    "    0 & \\text{with probability } p \\\\\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "The division by \\(1-p\\) keeps the expected activation unchanged, since  \n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\big[\\operatorname{Dropout}((\\hat{z}_{i+1})_j)\\big]\n",
    "= (1-p)\\,\\frac{(\\hat{z}_{i+1})_j}{1-p} + p \\cdot 0\n",
    "= (\\hat{z}_{i+1})_j\n",
    "$$\n",
    "\n",
    "**Important**: If the Dropout module has the flag `training=False`, you shouldn't \"dropout\" any activations. That is, dropout applies during training only, not during evaluation. Note that `training` is a flag in `nn.Module`.\n",
    "\n",
    "##### Parameters\n",
    "- `p` - the probability of an element to be zeroed.\n",
    "\n",
    "Utils in `python/needle/init/init_basic.py` might be helpful when implementing Dropout.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 91 deselected / 2 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_dropout_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m         [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_dropout_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m91 deselected\u001b[0m\u001b[32m in 0.14s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_dropout...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.50s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_dropout\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Residual\n",
    "`needle.nn.Residual(fn: Module)`\n",
    "\n",
    "Applies a residual or skip connection given module $\\mathcal{F}$ and input Tensor $x$, returning $\\mathcal{F}(x) + x$.\n",
    "##### Parameters\n",
    "- `fn` - module of type `needle.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 91 deselected / 2 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_residual_forward_1 \u001b[32mPASSED\u001b[0m\u001b[32m        [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_nn_residual_backward_1 \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m91 deselected\u001b[0m\u001b[32m in 0.14s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_nn_residual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting nn_residual...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.43s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"nn_residual\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Implement the `step` function of the following optimizers in `python/needle/optim.py`.\n",
    "Make sure that your optimizers _don't_ modify the gradients of tensors in-place.\n",
    "\n",
    "We have included some tests to ensure that you are not consuming excessive memory, which can happen if you are\n",
    "not using `.data` or `.detach()` in the right places, thus building an increasingly large computational graph\n",
    "(not just in the optimizers, but in the previous modules as well).\n",
    "You can ignore these tests, which include the string `memory_check` at your own discretion.\n",
    "\n",
    "___\n",
    "\n",
    "### SGD\n",
    "`needle.optim.SGD(params, lr=0.01, momentum=0.0, weight_decay=0.0)`\n",
    "\n",
    "Implements stochastic gradient descent (optionally with momentum, shown as $\\beta$ below). \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    u_{t+1} &= \\beta u_t + (1-\\beta) \\nabla_\\theta f(\\theta_t) \\\\\n",
    "    \\theta_{t+1} &= \\theta_t - \\alpha u_{t+1}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "##### Parameters\n",
    "- `params` - iterable of parameters of type `needle.nn.Parameter` to optimize\n",
    "- `lr` (*float*) - learning rate\n",
    "- `momentum` (*float*) - momentum factor\n",
    "- `weight_decay` (*float*) - weight decay (L2 penalty)\n",
    "\n",
    "Implementation of `clip_grad_norm` can be skipped for this homework.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -v -k \"test_optim_sgd\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 92 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_sgd_vanilla_1 \u001b[31mFAILED\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_optim_sgd_vanilla_1 ___________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_sgd_vanilla_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      "            learn_model_1d(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.SGD,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.01\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                momentum=\u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m3.207009\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:1879: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "args = (<function assert_allclose.<locals>.compare at 0x104df7f60>, array(3.2115598, dtype=float32), array(3.207009))\n",
      "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
      "\n",
      "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "                   ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
      "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
      "\u001b[1m\u001b[31mE           \u001b[0m\n",
      "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 1 (100%)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Max absolute difference: 0.00455077\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Max relative difference: 0.00141901\u001b[0m\n",
      "\u001b[1m\u001b[31mE            x: array(3.21156, dtype=float32)\u001b[0m\n",
      "\u001b[1m\u001b[31mE            y: array(3.207009)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/anaconda3/envs/ml_env/lib/python3.12/contextlib.py\u001b[0m:81: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_sgd_vanilla_1\u001b[0m - AssertionError: \n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m92 deselected\u001b[0m\u001b[31m in 0.26s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_optim_sgd_vanilla_1\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting optim_sgd...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[32m in 0.80s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"hw2\" -k \"optim_sgd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adam\n",
    "`needle.optim.Adam(params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-8, weight_decay=0.0)`\n",
    "\n",
    "Implements Adam algorithm, proposed in [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980). \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "u_{t+1} &= \\beta_1 u_t + (1-\\beta_1) \\nabla_\\theta f(\\theta_t) \\\\\n",
    "v_{t+1} &= \\beta_2 v_t + (1-\\beta_2) (\\nabla_\\theta f(\\theta_t))^2 \\\\\n",
    "\\hat{u}_{t+1} &= u_{t+1} / (1 - \\beta_1^t) \\quad \\text{(bias correction)} \\\\\n",
    "\\hat{v}_{t+1} &= v_{t+1} / (1 - \\beta_2^t) \\quad \\text{(bias correction)}\\\\\n",
    "\\theta_{t+1} &= \\theta_t - \\alpha \\hat{u_{t+1}}/(\\hat{v}_{t+1}^{1/2}+\\epsilon)\n",
    "\\end{split}\n",
    "    \\end{equation}\n",
    "\n",
    "**Important:** Pay attention to whether or not you are applying bias correction.\n",
    "\n",
    "##### Parameters\n",
    "- `params` - iterable of parameters of type `needle.nn.Parameter` to optimize\n",
    "- `lr` (*float*) - learning rate\n",
    "- `beta1` (*float*) - coefficient used for computing running average of gradient\n",
    "- `beta2` (*float*) - coefficient used for computing running average of square of gradient\n",
    "- `eps` (*float*) - term added to the denominator to improve numerical stability\n",
    "- `weight_decay` (*float*) - weight decay (L2 penalty)\n",
    "\n",
    "**Hint**: To help deal with memory issues, try to understand how to use `.data` or `.detach()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 86 deselected / 7 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_1 \u001b[31mFAILED\u001b[0m\u001b[31m                 [ 14%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_weight_decay_1 \u001b[31mFAILED\u001b[0m\u001b[31m    [ 28%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_batchnorm_1 \u001b[31mFAILED\u001b[0m\u001b[31m       [ 42%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_batchnorm_eval_mode_1 \u001b[31mFAILED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_layernorm_1 \u001b[31mFAILED\u001b[0m\u001b[31m       [ 71%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_weight_decay_bias_correction_1 \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_optim_adam_z_memory_check_1 \u001b[32mPASSED\u001b[0m\u001b[31m  [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ test_optim_adam_1 _______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_adam_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           learn_model_1d(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m3.703999\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2044: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:214: in learn_model_1d\n",
      "    \u001b[0mloss.backward()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:296: in backward\n",
      "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:390: in compute_gradient_of_variables\n",
      "    \u001b[0minput_grads = i.op.gradient(vi_bar, i)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:375: in gradient\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor(out_grad * Tensor(mask), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:318: in __mul__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:79: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
      "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:106: in realize_cached_data\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.ops.ops_mathematic.EWiseMul object at 0x10e0a6ea0>\n",
      "a = array([[-0.00460188, -0.00377785,  0.00829754, ..., -0.00790593,\n",
      "        -0.00608593, -0.0030183 ],\n",
      "       [ 0.0150096...8],\n",
      "       [ 0.01318878,  0.01748335,  0.00247987, ...,  0.01524307,\n",
      "         0.01190419, -0.00661498]], dtype=float32)\n",
      "b = array([[ True,  True, False, ..., False, False,  True],\n",
      "       [False,  True, False, ...,  True,  True,  True],\n",
      "      ...True],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [ True,  True, False, ..., False, False,  True]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, a: NDArray, b: NDArray):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.shape == b.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33mShape mismatch in multiplication\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00ma.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m b.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mb.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Expected float32 dtype, got bool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:54: AssertionError\n",
      "\u001b[31m\u001b[1m________________________ test_optim_adam_weight_decay_1 ________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_adam_weight_decay_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           learn_model_1d(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                weight_decay=\u001b[94m0.01\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m3.705134\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2059: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:214: in learn_model_1d\n",
      "    \u001b[0mloss.backward()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:296: in backward\n",
      "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:390: in compute_gradient_of_variables\n",
      "    \u001b[0minput_grads = i.op.gradient(vi_bar, i)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:375: in gradient\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor(out_grad * Tensor(mask), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:318: in __mul__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:79: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
      "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:106: in realize_cached_data\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.ops.ops_mathematic.EWiseMul object at 0x10e0e5fa0>\n",
      "a = array([[-0.00460188, -0.00377785,  0.00829754, ..., -0.00790593,\n",
      "        -0.00608593, -0.0030183 ],\n",
      "       [ 0.0150096...8],\n",
      "       [ 0.01318878,  0.01748335,  0.00247987, ...,  0.01524307,\n",
      "         0.01190419, -0.00661498]], dtype=float32)\n",
      "b = array([[ True,  True, False, ..., False, False,  True],\n",
      "       [False,  True, False, ...,  True,  True,  True],\n",
      "      ...True],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [ True,  True, False, ..., False, False,  True]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, a: NDArray, b: NDArray):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.shape == b.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33mShape mismatch in multiplication\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00ma.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m b.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mb.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Expected float32 dtype, got bool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:54: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________ test_optim_adam_batchnorm_1 __________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_adam_batchnorm_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           learn_model_1d(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(\u001b[90m\u001b[39;49;00m\n",
      "                    nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.BatchNorm1d(\u001b[94m32\u001b[39;49;00m), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                ),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                weight_decay=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m3.296256\u001b[39;49;00m, dtype=np.float32),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2075: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:214: in learn_model_1d\n",
      "    \u001b[0mloss.backward()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:296: in backward\n",
      "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:390: in compute_gradient_of_variables\n",
      "    \u001b[0minput_grads = i.op.gradient(vi_bar, i)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:375: in gradient\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor(out_grad * Tensor(mask), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:318: in __mul__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:79: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
      "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:106: in realize_cached_data\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.ops.ops_mathematic.EWiseMul object at 0x10e7a30b0>\n",
      "a = array([[-9.7520286e-03, -4.9000904e-03, -2.7582169e-02, ...,\n",
      "        -6.3871749e-02, -3.4240536e-02,  1.6493665e-04],\n",
      "...0457e-03,  5.8993534e-03, -7.2659028e-01, ...,\n",
      "         5.9987228e-02,  2.9523997e-02, -3.3085430e-03]], dtype=float32)\n",
      "b = array([[ True,  True, False, ..., False, False,  True],\n",
      "       [False,  True, False, ...,  True,  True,  True],\n",
      "      ...True],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [ True,  True, False, ..., False, False,  True]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, a: NDArray, b: NDArray):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.shape == b.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33mShape mismatch in multiplication\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00ma.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m b.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mb.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Expected float32 dtype, got bool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:54: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_optim_adam_batchnorm_eval_mode_1 _____________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_adam_batchnorm_eval_mode_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           learn_model_1d_eval(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(\u001b[90m\u001b[39;49;00m\n",
      "                    nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.BatchNorm1d(\u001b[94m32\u001b[39;49;00m), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                ),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                weight_decay=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m3.192054\u001b[39;49;00m, dtype=np.float32),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2093: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:248: in learn_model_1d_eval\n",
      "    \u001b[0mloss.backward()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:296: in backward\n",
      "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:390: in compute_gradient_of_variables\n",
      "    \u001b[0minput_grads = i.op.gradient(vi_bar, i)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:375: in gradient\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor(out_grad * Tensor(mask), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:318: in __mul__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:79: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
      "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:106: in realize_cached_data\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.ops.ops_mathematic.EWiseMul object at 0x10e714350>\n",
      "a = array([[-9.7520286e-03, -4.9000904e-03, -2.7582169e-02, ...,\n",
      "        -6.3871749e-02, -3.4240536e-02,  1.6493665e-04],\n",
      "...0457e-03,  5.8993534e-03, -7.2659028e-01, ...,\n",
      "         5.9987228e-02,  2.9523997e-02, -3.3085430e-03]], dtype=float32)\n",
      "b = array([[ True,  True, False, ..., False, False,  True],\n",
      "       [False,  True, False, ...,  True,  True,  True],\n",
      "      ...True],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [ True,  True, False, ..., False, False,  True]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, a: NDArray, b: NDArray):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.shape == b.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33mShape mismatch in multiplication\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00ma.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m b.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mb.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Expected float32 dtype, got bool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:54: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________ test_optim_adam_layernorm_1 __________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_adam_layernorm_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           learn_model_1d(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(\u001b[90m\u001b[39;49;00m\n",
      "                    nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.LayerNorm1d(\u001b[94m32\u001b[39;49;00m), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                ),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.01\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                weight_decay=\u001b[94m0.01\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m2.82192\u001b[39;49;00m, dtype=np.float32),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2111: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:214: in learn_model_1d\n",
      "    \u001b[0mloss.backward()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:296: in backward\n",
      "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:390: in compute_gradient_of_variables\n",
      "    \u001b[0minput_grads = i.op.gradient(vi_bar, i)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:375: in gradient\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor(out_grad * Tensor(mask), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:318: in __mul__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:79: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
      "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:106: in realize_cached_data\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.ops.ops_mathematic.EWiseMul object at 0x10e0e6b70>\n",
      "a = array([[-2.0888436e-03, -2.1664414e-03,  1.0105689e-03, ...,\n",
      "        -4.8720893e-03, -4.4500781e-03, -1.3627942e-03],\n",
      "...3910e-03,  3.0395116e-03, -1.6665088e-03, ...,\n",
      "         2.1733607e-03,  8.6941390e-04, -4.2820959e-03]], dtype=float32)\n",
      "b = array([[ True,  True, False, ..., False, False,  True],\n",
      "       [False,  True, False, ...,  True,  True,  True],\n",
      "      ...True],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [ True,  True, False, ..., False, False,  True]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, a: NDArray, b: NDArray):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.shape == b.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33mShape mismatch in multiplication\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00ma.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m b.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mb.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Expected float32 dtype, got bool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:54: AssertionError\n",
      "\u001b[31m\u001b[1m________________ test_optim_adam_weight_decay_bias_correction_1 ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_optim_adam_weight_decay_bias_correction_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           learn_model_1d(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m64\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94m16\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mlambda\u001b[39;49;00m z: nn.Sequential(nn.Linear(\u001b[94m64\u001b[39;49;00m, \u001b[94m32\u001b[39;49;00m), nn.ReLU(), nn.Linear(\u001b[94m32\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m)),\u001b[90m\u001b[39;49;00m\n",
      "                ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "                lr=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                weight_decay=\u001b[94m0.01\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m3.705134\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2129: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:214: in learn_model_1d\n",
      "    \u001b[0mloss.backward()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:296: in backward\n",
      "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:390: in compute_gradient_of_variables\n",
      "    \u001b[0minput_grads = i.op.gradient(vi_bar, i)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:375: in gradient\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor(out_grad * Tensor(mask), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:318: in __mul__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m needle.ops.EWiseMul()(\u001b[96mself\u001b[39;49;00m, other)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:79: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:241: in make_from_op\n",
      "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:106: in realize_cached_data\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.ops.ops_mathematic.EWiseMul object at 0x10e0a5fa0>\n",
      "a = array([[-0.00460188, -0.00377785,  0.00829754, ..., -0.00790593,\n",
      "        -0.00608593, -0.0030183 ],\n",
      "       [ 0.0150096...8],\n",
      "       [ 0.01318878,  0.01748335,  0.00247987, ...,  0.01524307,\n",
      "         0.01190419, -0.00661498]], dtype=float32)\n",
      "b = array([[ True,  True, False, ..., False, False,  True],\n",
      "       [False,  True, False, ...,  True,  True,  True],\n",
      "      ...True],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [ True,  True, False, ..., False, False,  True]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, a: NDArray, b: NDArray):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.shape == b.shape, \u001b[33m\"\u001b[39;49;00m\u001b[33mShape mismatch in multiplication\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m a.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00ma.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m b.dtype == \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mExpected float32 dtype, got \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mb.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Expected float32 dtype, got bool\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:54: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_adam_1\u001b[0m - AssertionError: Expected float32 dtype, got bool\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_adam_weight_decay_1\u001b[0m - AssertionError: Expected float32 dtype, got bool\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_adam_batchnorm_1\u001b[0m - AssertionError: Expected float32 dtype, got bool\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_adam_batchnorm_eval_mode_1\u001b[0m - AssertionError: Expected float32 dtype, got bool\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_adam_layernorm_1\u001b[0m - AssertionError: Expected float32 dtype, got bool\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_optim_adam_weight_decay_bias_correction_1\u001b[0m - AssertionError: Expected float32 dtype, got bool\n",
      "\u001b[31m================== \u001b[31m\u001b[1m6 failed\u001b[0m, \u001b[32m1 passed\u001b[0m, \u001b[33m86 deselected\u001b[0m\u001b[31m in 0.44s\u001b[0m\u001b[31m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_optim_adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting optim_adam...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 failed\n",
      "Grader test 6 passed\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ submit_optim_adam _______________________________\u001b[0m\n",
      "\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1msubmit_optim_adam\u001b[0m - Failed\n",
      "\u001b[31m================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m18 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 1.31s\u001b[0m\u001b[31m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"optim_adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "In this question, you will implement two data primitives: `needle.data.DataLoader` and `needle.data.Dataset`. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the `Dataset` to enable easy access to the samples. \n",
    "\n",
    "For this question, you will be working in the `python/needle/data` directory. \n",
    "\n",
    "### Transformations\n",
    "\n",
    "First we will implement a few transformations that are helpful when working with images. We will stick with a horizontal flip and a random crop for now. Fill out the following functions in `needle/data/data_transforms.py`.\n",
    "___ \n",
    "\n",
    "#### RandomFlipHorizontal\n",
    "`needle.data.RandomFlipHorizontal(p = 0.5)`\n",
    "\n",
    "Flips the image horizontally, with probability `p`.\n",
    "\n",
    "##### Parameters\n",
    "- `p` (*float*) - The probability of flipping the input image.\n",
    "___\n",
    "\n",
    "#### RandomCrop\n",
    "`needle.data.RandomCrop(padding=3)`\n",
    "\n",
    "Padding is added to all sides of the image, and then the image is cropped back to it's original size at a random location. Returns an image the same size as the original image.\n",
    "\n",
    "##### Parameters\n",
    "- `padding` (*int*) - The padding on each border of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 92 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py::test_flip_horizontal \u001b[31mFAILED\u001b[0m\u001b[31m                      [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________________ test_flip_horizontal _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_horizontal\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        tform = ndl.data.RandomFlipHorizontal()\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        a = np.array(\u001b[90m\u001b[39;49;00m\n",
      "            [\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6788795301189603\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7206326547259168\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5820197920751071\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5373732294490107\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7586156243223572\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.10590760718779213\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4736004193466574\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18633234332675996\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7369181771289581\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21655035442437187\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13521817340545206\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3241410077932141\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.14967486718368317\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.22232138825158765\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.38648898112586194\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9025984755294046\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4499499899112276\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6130634578841324\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9023485831739843\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09928035035897387\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9698090677467488\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6531400357979377\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.17090958513604515\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.358152166969525\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7506861412184562\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6078306687154678\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3250472290083525\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.038425426472734725\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.634274057957335\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9589492686245203\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6527903170054908\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6350588736035638\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9952995676778876\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5818503294385343\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4143685882263688\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4746975022884129\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6235101011318682\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.33800761483889175\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6747523222590207\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3172017420692961\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.778345482025909\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9495710534507421\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6625268669500443\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.013571635612109834\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6228460955466695\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6736596308357894\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9719450024996658\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.878193471347177\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5096243767199001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05571469370160631\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4511592145209281\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.019987665408758737\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.44171092124884537\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9795867288127285\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3594444639693215\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4808935308361628\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6886611828057704\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8804758892525955\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9182354663621447\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21682213762754288\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "            ]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        b = np.array(\u001b[90m\u001b[39;49;00m\n",
      "            [\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6788795301189603\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7206326547259168\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5820197920751071\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5373732294490107\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7586156243223572\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.10590760718779213\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4736004193466574\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18633234332675996\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7369181771289581\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21655035442437187\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13521817340545206\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3241410077932141\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.14967486718368317\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.22232138825158765\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.38648898112586194\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9025984755294046\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4499499899112276\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6130634578841324\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9023485831739843\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09928035035897387\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9698090677467488\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6531400357979377\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.17090958513604515\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.358152166969525\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7506861412184562\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6078306687154678\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3250472290083525\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.038425426472734725\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.634274057957335\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9589492686245203\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6527903170054908\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6350588736035638\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9952995676778876\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5818503294385343\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4143685882263688\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4746975022884129\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6235101011318682\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.33800761483889175\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6747523222590207\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3172017420692961\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.778345482025909\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9495710534507421\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6625268669500443\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.013571635612109834\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6228460955466695\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6736596308357894\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9719450024996658\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.878193471347177\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5096243767199001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05571469370160631\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4511592145209281\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.019987665408758737\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.44171092124884537\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9795867288127285\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3594444639693215\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4808935308361628\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6886611828057704\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8804758892525955\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9182354663621447\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21682213762754288\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "            ]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      ">       np.testing.assert_allclose(tform(a), b)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:213: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.data_transforms.RandomFlipHorizontal object at 0x104c0f140>\n",
      "img = array([[[0.67887953, 0.72063265, 0.58201979, 0.53737323, 0.75861562],\n",
      "        [0.10590761, 0.47360042, 0.18633234, 0.7....01998767, 0.44171092, 0.97958673, 0.35944446],\n",
      "        [0.48089353, 0.68866118, 0.88047589, 0.91823547, 0.21682214]]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__call__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, img):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Horizonally flip an image, specified as an H x W x C NDArray.\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        img: H x W x C NDArray of an image\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        H x W x C NDArray corresponding to image flipped with probability self.p\u001b[39;49;00m\n",
      "    \u001b[33m    Note: use the provided code to provide randomness, for easier testing\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        flip_img = np.random.rand() < \u001b[96mself\u001b[39;49;00m.p\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/data_transforms.py\u001b[0m:23: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1mtest_flip_horizontal\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m92 deselected\u001b[0m\u001b[31m in 0.21s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 92 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py::test_random_crop \u001b[31mFAILED\u001b[0m\u001b[31m                          [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________________ test_random_crop _______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_random_crop\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        tform = ndl.data.RandomCrop(\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        a = np.array(\u001b[90m\u001b[39;49;00m\n",
      "            [\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.26455561210462697\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7742336894342167\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.45615033221654855\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5684339488686485\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.018789800436355142\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6176354970758771\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6120957227224214\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6169339968747569\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9437480785146242\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6818202991034834\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.359507900573786\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.43703195379934145\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6976311959272649\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.06022547162926983\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6667667154456677\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6706378696181594\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2103825610738409\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1289262976548533\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.31542835092418386\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3637107709426226\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5701967704178796\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.43860151346232035\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9883738380592262\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.10204481074802807\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2088767560948347\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.16130951788499626\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6531083254653984\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2532916025397821\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4663107728563063\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.24442559200160274\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.15896958364551972\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.11037514116430513\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6563295894652734\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1381829513486138\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1965823616800535\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3687251706609641\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8209932298479351\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09710127579306127\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8379449074988039\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09609840789396307\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9764594650133958\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4686512016477016\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9767610881903371\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.604845519745046\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7392635793983017\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.039187792254320675\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2828069625764096\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1201965612131689\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.29614019752214493\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.11872771895424405\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.317983179393976\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.41426299451466997\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.06414749634878436\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6924721193700198\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5666014542065752\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2653894909394454\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5232480534666997\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09394051075844168\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5759464955561793\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9292961975762141\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.31856895245132366\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6674103799636817\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13179786240439217\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7163272041185655\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2894060929472011\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18319136200711683\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5865129348100832\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.020107546187493552\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8289400292173631\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.004695476192547066\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6778165367962301\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.27000797319216485\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7351940221225949\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9621885451174382\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.24875314351995803\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5761573344178369\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.592041931271839\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5722519057908734\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2230816326406183\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.952749011516985\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.44712537861762736\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8464086724711278\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6994792753175043\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.29743695085513366\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8137978197024772\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.39650574084698464\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8811031971111616\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5812728726358587\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8817353618548528\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6925315900777659\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7252542798196405\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5013243819267023\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9560836347232239\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6439901992296374\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4238550485581797\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6063932141279244\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.019193198309333526\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.30157481667454933\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.660173537492685\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.29007760721044407\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6180154289988415\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.42876870094576613\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13547406422245023\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.29828232595603077\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5699649107012649\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5908727612481732\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5743252488495788\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6532008198571336\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6521032700016889\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.43141843543397396\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.896546595851063\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.36756187004789653\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4358649252656268\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8919233550156721\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8061939890460857\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7038885835403663\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.10022688731230112\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9194826137446735\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7142412995491114\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9988470065678665\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.14944830465799375\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8681260573682142\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.16249293467637482\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6155595642838442\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.12381998284944151\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8480082293222344\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8073189587250107\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5691007386145933\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.40718329722599966\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.06916699545513805\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6974287731445636\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.45354268267806885\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7220555994703479\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8663823259286292\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9755215050028858\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.855803342392611\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.011714084185001972\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3599780644783639\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.729990562424058\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.17162967726144052\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5210366062041293\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05433798833925363\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.19999652489640007\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.01852179446061397\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7936977033574206\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.22392468806038013\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3453516806969027\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9280812934655909\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7044144019235328\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.03183892953130785\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.16469415649791275\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6214784014997635\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5772285886041676\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.23789282137450862\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9342139979247938\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.613965955965896\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5356328030249583\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.589909976354571\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7301220295167696\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.31194499547960186\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3982210622160919\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.20984374897512215\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18619300588033616\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9443723899839336\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7395507950492876\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4904588086175671\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.22741462797332324\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.25435648177039294\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05802916032387562\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4344166255581208\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3117958819941026\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6963434888154595\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3777518392924809\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1796036775596348\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.02467872839133123\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.06724963146324858\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6793927734985673\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4536968445560453\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5365792111087222\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8966712930403421\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9903389473967044\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21689698439847394\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6630782031001008\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.26332237673715064\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.02065099946572868\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7583786538361414\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.32001715082246784\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.38346389417189797\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5883171135536057\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8310484552361904\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6289818435911487\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8726506554473953\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.27354203481563577\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7980468339125637\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1856359443059522\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9527916569719446\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6874882763878153\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21550767711355845\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9473705904889242\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7308558067701578\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.25394164259502583\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.21331197736748198\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5182007139306632\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.025662718054531575\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2074700754411094\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.42468546875150626\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.37416998033422555\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4635754243648107\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2776287062947319\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5867843464581688\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8638556059232314\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.11753185596203308\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5173791071541142\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1320681063451533\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7168596811925937\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.39605970280729375\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.565421311858509\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18327983621407862\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.14484775934337724\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.48805628064895457\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3556127378499556\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.940431945252813\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7653252538069653\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7486636198505473\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9037197397459334\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.08342243544201855\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5521924699224066\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5844760689557689\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.961936378547229\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.29214752679254885\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.24082877991544682\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.10029394226549782\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.016429629591474204\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9295293167921905\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.66991654659091\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7851529120231378\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2817301057539491\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5864101661863267\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.06395526612098112\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4856275959346229\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9774951397444468\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8765052453165908\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.33815895183684563\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9615701545414985\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2317016264712045\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9493188224156814\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9413777047064986\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7992025873523917\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6304479368667911\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.874287966624947\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2930202845077967\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8489435553129182\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6178766919175238\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.01323685775889949\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.34723351793221957\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.14814086094816503\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9818293898182532\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.47837030703998806\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4973913654986627\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6394725163987236\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3685846061296175\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13690027168559893\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8221177331942455\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18984791190275796\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.511318982546456\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.22431702897473926\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09784448449403405\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8621915174216833\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9729194890231303\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9608346580630002\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.906555499221179\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7740473326986388\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3331451520286419\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.08110138998799676\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.40724117141380733\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.23223414217094274\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13248763475798297\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05342718178682526\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7255943642105788\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.011427458625031028\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7705807485027762\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.14694664540037505\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.07952208258675575\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.08960303423860538\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6720478073539145\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.24536720985284477\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.42053946668009845\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5573687913239169\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8605511738287938\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7270442627113283\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.27032790523871464\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1314827992911276\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05537432042119794\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3015986344809425\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.26211814923967824\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.45614056680047965\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6832813355476804\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6956254456388572\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.28351884658216664\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3799269559001205\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18115096173690304\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7885455123065187\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0568480764332403\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6969972417249873\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7786953959411034\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7774075618487531\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.25942256434535493\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.37381313793256143\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.587599635196389\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.272821902424467\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3708527992178887\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.19705428018563964\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4598558837560074\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.044612301254114084\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.799795884570618\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.07695644698663273\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.518835148831526\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3068100995451961\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5775429488313755\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9594333408334251\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6455702444560039\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.03536243575549092\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.43040243950806123\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5100168523182502\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.536177494703452\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6813925106038379\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2775960977317661\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1288605654663202\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.39267567654709434\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9564057227959488\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18713089175084474\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.903983954928237\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5438059500773263\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4569114216457658\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8820414102298896\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.45860396176858587\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7241676366115433\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.399025321703102\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9040443929009577\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6900250201912274\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6996220542505167\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3277204015571189\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7567786427368892\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6360610554471413\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.24002027337970955\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.16053882248525642\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7963914745173317\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9591666030352225\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.45813882726004285\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5909841653236849\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8577226441935546\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.45722345335385706\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9518744768327362\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5757511620448724\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.820767120701315\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9088437184127384\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8155238187685688\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.15941446344895593\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6288984390617004\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3984342586196771\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0627129520233457\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.42403225188984195\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2586840668894077\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8490383084285108\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.03330462654669619\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9589827218634736\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3553688484719296\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3567068904025429\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.01632850268370789\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.18523232523618394\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4012595008036087\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9292914173027139\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.09961493022127133\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9453015334790795\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8694885305466322\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4541623969075518\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.32670088176826007\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.23274412927905685\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6144647064768743\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.03307459147550562\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.015606064446828216\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.42879572249823783\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0680740739747202\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2519409882460929\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.22116091534608384\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2531911937228519\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13105523121525775\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.01203622289765427\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.11548429713874808\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6184802595127479\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9742562128180503\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9903450015608939\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4090540953730616\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.16295442604660537\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6387617573665293\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.49030534654873714\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9894097772844315\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0653042071517802\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7832344383138131\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2883984973314939\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.241418620076574\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.662504571532676\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.24606318499096447\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6658591175591877\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.5173085172022888\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4240889884358493\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.554687808661419\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.28705151991962974\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7065747062729789\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.414856869333564\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.36054556048589226\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8286569145557378\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9249669119531921\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.046007310887296926\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2326269928297655\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.34851936949256324\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8149664793702474\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9854914276432976\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9689717046703518\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9049483455499269\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2965562650640299\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9920112434144741\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2494200410564512\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.1059061548822322\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.9509526110553941\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2334202554680963\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6897682650777505\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.05835635898058866\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7307090991274762\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8817202123338397\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.2724368954659625\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.37905689607742854\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3742961833209161\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.7487882575401331\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.23780724253903884\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.171853099047643\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.4492916486877381\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.3044684073773195\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.8391891222586524\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.23774182601563876\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "            ]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        b = np.array(\u001b[90m\u001b[39;49;00m\n",
      "            [\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "                [[\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m], [\u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m, \u001b[94m0.0\u001b[39;49;00m]],\u001b[90m\u001b[39;49;00m\n",
      "            ]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      ">       np.testing.assert_allclose(tform(a), b)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:2218: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.data_transforms.RandomCrop object at 0x104e33cb0>\n",
      "img = array([[[0.26455561, 0.77423369, 0.45615033, 0.56843395, 0.0187898 ],\n",
      "        [0.6176355 , 0.61209572, 0.616934  , 0.9....3790569 , 0.37429618, 0.74878826, 0.23780724],\n",
      "        [0.1718531 , 0.44929165, 0.30446841, 0.83918912, 0.23774183]]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__call__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, img):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Zero pad and then randomly crop an image.\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m         img: H x W x C NDArray of an image\u001b[39;49;00m\n",
      "    \u001b[33m    Return\u001b[39;49;00m\n",
      "    \u001b[33m        H x W x C NDArray of cliped image\u001b[39;49;00m\n",
      "    \u001b[33m    Note: generate the image shifted by shift_x, shift_y specified below\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        shift_x, shift_y = np.random.randint(low=-\u001b[96mself\u001b[39;49;00m.padding, high=\u001b[96mself\u001b[39;49;00m.padding+\u001b[94m1\u001b[39;49;00m, size=\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/data_transforms.py\u001b[0m:41: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1mtest_random_crop\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m92 deselected\u001b[0m\u001b[31m in 0.29s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"flip_horizontal\"\n",
    "!python3 -m pytest -v -k \"random_crop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py \n",
      "Submitting flip_horizontal...\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ submit_flip_horizontal ____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_flip_horizontal\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        tform = ndl.data.RandomFlipHorizontal(\u001b[94m0.5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m _ \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[94m2\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            size_a, size_b, size_c = (\u001b[90m\u001b[39;49;00m\n",
      "                np.random.randint(\u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "                np.random.randint(\u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "                np.random.randint(\u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      ">           mugrade.submit(tform(np.random.rand(size_a, size_b, size_c)))\u001b[90m\u001b[39;49;00m\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:1438: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.data_transforms.RandomFlipHorizontal object at 0x12b022330>\n",
      "img = array([[[0.84426575, 0.85794562],\n",
      "        [0.84725174, 0.6235637 ],\n",
      "        [0.38438171, 0.29753461],\n",
      "        [0.05671298, 0.27265629]]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__call__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, img):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Horizonally flip an image, specified as an H x W x C NDArray.\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        img: H x W x C NDArray of an image\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        H x W x C NDArray corresponding to image flipped with probability self.p\u001b[39;49;00m\n",
      "    \u001b[33m    Note: use the provided code to provide randomness, for easier testing\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        flip_img = np.random.rand() < \u001b[96mself\u001b[39;49;00m.p\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/data_transforms.py\u001b[0m:23: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1msubmit_flip_horizontal\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[31m in 0.17s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py \n",
      "Submitting random_crop...\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ submit_random_crop ______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_random_crop\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        tform = ndl.data.RandomCrop(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m _ \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[94m2\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            size_a, size_b, size_c = (\u001b[90m\u001b[39;49;00m\n",
      "                np.random.randint(\u001b[94m4\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "                np.random.randint(\u001b[94m4\u001b[39;49;00m, \u001b[94m6\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "                np.random.randint(\u001b[94m4\u001b[39;49;00m, \u001b[94m7\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      ">           mugrade.submit(tform(np.random.rand(size_a, size_b, size_c)))\u001b[90m\u001b[39;49;00m\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:10666: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.data_transforms.RandomCrop object at 0x11e4daf30>\n",
      "img = array([[[0.84426575, 0.85794562, 0.84725174, 0.6235637 , 0.38438171],\n",
      "        [0.29753461, 0.05671298, 0.27265629, 0.4....05571469, 0.45115921, 0.01998767, 0.44171092],\n",
      "        [0.97958673, 0.35944446, 0.48089353, 0.68866118, 0.88047589]]])\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__call__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, img):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Zero pad and then randomly crop an image.\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m         img: H x W x C NDArray of an image\u001b[39;49;00m\n",
      "    \u001b[33m    Return\u001b[39;49;00m\n",
      "    \u001b[33m        H x W x C NDArray of cliped image\u001b[39;49;00m\n",
      "    \u001b[33m    Note: generate the image shifted by shift_x, shift_y specified below\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        shift_x, shift_y = np.random.randint(low=-\u001b[96mself\u001b[39;49;00m.padding, high=\u001b[96mself\u001b[39;49;00m.padding+\u001b[94m1\u001b[39;49;00m, size=\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/data_transforms.py\u001b[0m:41: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1msubmit_random_crop\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[31m in 0.22s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"flip_horizontal\"\n",
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"random_crop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset is in charge of what your data is (e.g., an image/label pair) and how to get a single sample. The Dataloader is in charge of how your data is fed into training (e.g., batching, shuffling, iterating over epochs).\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Each **subclass** of the  `Dataset`class must implement three functions: `__init__`, `__len__`, and `__getitem__`.\n",
    "* The `__init__` function initializes the images, labels, and transforms.\n",
    "* The `__len__` function returns the number of samples in the dataset.\n",
    "* The `__getitem__` function retrieves a sample from the dataset at a given index `idx`, **calls the transform functions on the image (if applicable)**, converts the image and label to a numpy array (the data will be converted to Tensors elsewhere). The output of `__getitem__` and `__next__` should be NDArrays, and you should follow the shapes such that you're accessing an array of size (Datapoint Number, Feature Dim 1, Feature Dim 2, ...). \n",
    "\n",
    "Fill out these functions in the `MNISTDataset` class in `needle/data/datasets/mnist_dataset.py`. You can use your solution to `parse_mnist` from the previous homework for the `__init__` function.\n",
    "\n",
    "### MNISTDataset (subclass of Dataset)\n",
    "`needle.data.MNISTDataset(image_filename, label_filename, transforms)`\n",
    "\n",
    "##### Parameters\n",
    "- `image_filename` - path of file containing images\n",
    "- `label_filename` - path of file containing labels\n",
    "- `transforms` - an optional list of transforms to apply to data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 92 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py::test_mnist_dataset \u001b[31mFAILED\u001b[0m\u001b[31m                        [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ test_mnist_dataset ______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mnist_dataset\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Test dataset sizing\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       mnist_train_dataset = ndl.data.MNISTDataset(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-images-idx3-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-labels-idx1-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:10689: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.datasets.mnist_dataset.MNISTDataset object at 0x10247f680>\n",
      "image_filename = 'data/train-images-idx3-ubyte.gz'\n",
      "label_filename = 'data/train-labels-idx1-ubyte.gz', transforms = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        image_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        label_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        transforms: Optional[List] = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/datasets/mnist_dataset.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1mtest_mnist_dataset\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m92 deselected\u001b[0m\u001b[31m in 0.20s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_mnist_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py \n",
      "Submitting mnist_dataset...\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________________ submit_mnist_dataset _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_mnist_dataset\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       mnist_train_dataset = ndl.data.MNISTDataset(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-images-idx3-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-labels-idx1-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:10815: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.datasets.mnist_dataset.MNISTDataset object at 0x11f7291f0>\n",
      "image_filename = 'data/train-images-idx3-ubyte.gz'\n",
      "label_filename = 'data/train-labels-idx1-ubyte.gz', transforms = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        image_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        label_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        transforms: Optional[List] = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/datasets/mnist_dataset.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1msubmit_mnist_dataset\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[31m in 0.24s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"mnist_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "`needle.data.Dataloader(dataset: Dataset, batch_size: Optional[int] = 1, shuffle: bool = False)`\n",
    "\n",
    "\n",
    "In `needle/data/data_basic.py`, the Dataloader class provides an interface for assembling mini-batches of examples suitable for training using SGD-based approaches, backed by a `Dataset` object.  In order to build the typical Dataloader interface (allowing users to iterate over all the mini-batches in the dataset), you will need to implement the `__iter__()` and `__next__()` calls in the class:\n",
    "* `__iter__()` is called at the start of a new epoch (i.e., whenever you begin looping over the dataloader).\n",
    "* `__next__()` is called once per batch until the epoch is finished.\n",
    "\n",
    "Please note that subsequent calls to next will require you to return the following batches, so next is not a pure function.\n",
    "\n",
    "##### Purpose\n",
    "\n",
    "Combines a dataset and a sampler, and provides an iterable over the given dataset. \n",
    "\n",
    "##### Parameters\n",
    "- `dataset` - `needle.data.Dataset` - a dataset \n",
    "- `batch_size` - `int` - what batch size to serve the data in \n",
    "- `shuffle` - `bool` - set to ``True`` to reshuffle the data **at the beginning of every epoch**, default ``False``.\n",
    "___ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 91 deselected / 2 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py::test_dataloader_mnist \u001b[31mFAILED\u001b[0m\u001b[31m                     [ 50%]\u001b[0m\n",
      "tests/hw2/test_data.py::test_dataloader_ndarray \u001b[31mFAILED\u001b[0m\u001b[31m                   [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ test_dataloader_mnist _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dataloader_mnist\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        batch_size = \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       mnist_train_dataset = ndl.data.MNISTDataset(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-images-idx3-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-labels-idx1-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:10844: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.datasets.mnist_dataset.MNISTDataset object at 0x104052030>\n",
      "image_filename = 'data/train-images-idx3-ubyte.gz'\n",
      "label_filename = 'data/train-labels-idx1-ubyte.gz', transforms = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        image_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        label_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        transforms: Optional[List] = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/datasets/mnist_dataset.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[31m\u001b[1m___________________________ test_dataloader_ndarray ____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_dataloader_ndarray\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m batch_size \u001b[95min\u001b[39;49;00m [\u001b[94m1\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "            np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            train_dataset = ndl.data.NDArrayDataset(np.random.rand(\u001b[94m100\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "            train_dataloader = ndl.data.DataLoader(\u001b[90m\u001b[39;49;00m\n",
      "                dataset=train_dataset, batch_size=batch_size, shuffle=\u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mfor\u001b[39;49;00m i, batch \u001b[95min\u001b[39;49;00m \u001b[96menumerate\u001b[39;49;00m(train_dataloader):\u001b[90m\u001b[39;49;00m\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:10900: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.data_basic.DataLoader object at 0x11bd4b3e0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__iter__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/data_basic.py\u001b[0m:63: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1mtest_dataloader_mnist\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1mtest_dataloader_ndarray\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m91 deselected\u001b[0m\u001b[31m in 0.28s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_dataloader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_data.py \n",
      "Submitting dataloader...\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ submit_dataloader _______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_dataloader\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        batch_size = \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       mnist_train_dataset = ndl.data.MNISTDataset(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-images-idx3-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mdata/train-labels-idx1-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_data.py\u001b[0m:10957: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.datasets.mnist_dataset.MNISTDataset object at 0x11cd0c1a0>\n",
      "image_filename = 'data/train-images-idx3-ubyte.gz'\n",
      "label_filename = 'data/train-labels-idx1-ubyte.gz', transforms = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        image_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        label_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        transforms: Optional[List] = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/datasets/mnist_dataset.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_data.py::\u001b[1msubmit_dataloader\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[31m in 0.28s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"dataloader\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Given you have now implemented all the necessary components for our neural network library, let's build and train an MLP ResNet. For this question, you will be working in `apps/mlp_resnet.py`. First, fill out the functions `ResidualBlock` and `MLPResNet` as described below:\n",
    "\n",
    "### ResidualBlock\n",
    "`ResidualBlock(dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=0.1)`\n",
    "\n",
    "Implements a residual block as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/dlsyscourse/hw2/blob/f4c994506f2c76d7fdcc5a711a483e31b189afaa/figures/residualblock.png?raw=true\" alt=\"Residual Block\"/>\n",
    "</p>\n",
    "\n",
    "**NOTE**: if the figure does not render, please see the figure in the `figures` directory.\n",
    "\n",
    "where the first linear layer has `in_features=dim` and `out_features=hidden_dim`, and the last linear layer has `out_features=dim`. Returns the block as type `nn.Module`. \n",
    "\n",
    "##### Parameters\n",
    "- `dim` (*int*) - input dim\n",
    "- `hidden_dim` (*int*) - hidden dim\n",
    "- `norm` (*nn.Module*) - normalization method\n",
    "- `drop_prob` (*float*) - dropout probability\n",
    "\n",
    "___\n",
    "\n",
    "### MLPResNet\n",
    "`MLPResNet(dim, hidden_dim=100, num_blocks=3, num_classes=10, norm=nn.BatchNorm1d, drop_prob=0.1)`\n",
    "\n",
    "Implements an MLP ResNet as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/dlsyscourse/hw2/blob/f4c994506f2c76d7fdcc5a711a483e31b189afaa/figures/mlp_resnet.png?raw=true\" alt=\"MLP Resnet\"/>\n",
    "</p>\n",
    "\n",
    "where the first linear layer has `in_features=dim` and `out_features=hidden_dim`, and each ResidualBlock has `dim=hidden_dim` and `hidden_dim=hidden_dim//2`. Returns a network of type `nn.Module`.\n",
    "\n",
    "##### Parameters\n",
    "- `dim` (*int*) - input dim\n",
    "- `hidden_dim` (*int*) - hidden dim\n",
    "- `num_blocks` (*int*) - number of ResidualBlocks\n",
    "- `num_classes` (*int*) - number of classes\n",
    "- `norm` (*nn.Module*) - normalization method\n",
    "- `drop_prob` (*float*) - dropout probability (0.1)\n",
    "\n",
    "**Note**: Modules should be initialized to match the order of execution in the Resnet.\n",
    "___ \n",
    "\n",
    "Once you have the deep learning model architecture correct, let's train the network using our new neural network library components. Specifically, implement the functions `epoch` and `train_mnist`.\n",
    "\n",
    "### Epoch\n",
    "\n",
    "`epoch(dataloader, model, opt=None)`\n",
    "\n",
    "Executes one epoch of training or evaluation, iterating over the entire training dataset once (just like `nn_epoch` from previous homeworks). Returns the average error rate (as a *float*) and the average loss over all samples (as a *float*). Set the model to `training` mode at the beginning of the function if `opt` is given; set the model to `eval` if `opt` is not given (i.e. `None`). When setting the modes, use `.train()` and `.eval()` instead of modifying the training attribute.\n",
    "\n",
    "##### Parameters\n",
    "- `dataloader` (*`needle.data.DataLoader`*) - dataloader returning samples from the training dataset\n",
    "- `model` (*`needle.nn.Module`*) - neural network\n",
    "- `opt` (*`needle.optim.Optimizer`*) - optimizer instance, or `None`\n",
    "\n",
    "___\n",
    "\n",
    "### Train Mnist\n",
    "\n",
    "`train_mnist(batch_size=100, epochs=10, optimizer=ndl.optim.Adam, lr=0.001, weight_decay=0.001, hidden_dim=100, data_dir=\"data\")`\n",
    "                \n",
    "Initializes a training dataloader (with `shuffle` set to `True`) and a test dataloader for MNIST data, and trains an `MLPResNet` using the given optimizer (if `opt` is not None) and the softmax loss for a given number of epochs. Returns a tuple of the training error, training loss, test error, test loss computed in the last epoch of training. If any parameters are not specified, use the default parameters.\n",
    "\n",
    "##### Parameters\n",
    "- `batch_size` (*int*) - batch size to use for train and test dataloader\n",
    "- `epochs` (*int*) - number of epochs to train for\n",
    "- `optimizer` (*`needle.optim.Optimizer` type*) - optimizer type to use\n",
    "- `lr` (*float*) - learning rate \n",
    "- `weight_decay` (*float*) - weight decay\n",
    "- `hidden_dim` (*int*) - hidden dim for `MLPResNet`\n",
    "- `data_dir` (*str*) - directory containing MNIST image/label files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0 -- /opt/homebrew/anaconda3/envs/ml_env/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 93 items / 83 deselected / 10 selected                               \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_residual_block_num_params_1 \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_residual_block_num_params_2 \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_residual_block_forward_1 \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_resnet_num_params_1 \u001b[31mFAILED\u001b[0m\u001b[31m      [ 40%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_resnet_num_params_2 \u001b[31mFAILED\u001b[0m\u001b[31m      [ 50%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_resnet_forward_1 \u001b[31mFAILED\u001b[0m\u001b[31m         [ 60%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_resnet_forward_2 \u001b[31mFAILED\u001b[0m\u001b[31m         [ 70%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_train_epoch_1 \u001b[31mFAILED\u001b[0m\u001b[31m            [ 80%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_eval_epoch_1 \u001b[31mFAILED\u001b[0m\u001b[31m             [ 90%]\u001b[0m\n",
      "tests/hw2/test_nn_and_optim.py::test_mlp_train_mnist_1 \u001b[31mFAILED\u001b[0m\u001b[31m            [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________ test_mlp_residual_block_num_params_1 _____________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_residual_block_num_params_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           residual_block_num_params(\u001b[94m15\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, nn.BatchNorm1d),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m111\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2227: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:375: in residual_block_num_params\n",
      "    \u001b[0mmodel = ResidualBlock(dim, hidden_dim, norm)\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 15, hidden_dim = 2, norm = <class 'needle.nn.nn_basic.BatchNorm1d'>\n",
      "drop_prob = 0.1\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mResidualBlock\u001b[39;49;00m(dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=\u001b[94m0.1\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:16: NotImplementedError\n",
      "\u001b[31m\u001b[1m_____________________ test_mlp_residual_block_num_params_2 _____________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_residual_block_num_params_2\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           residual_block_num_params(\u001b[94m784\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m, nn.LayerNorm1d),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m159452\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2236: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:375: in residual_block_num_params\n",
      "    \u001b[0mmodel = ResidualBlock(dim, hidden_dim, norm)\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 784, hidden_dim = 100, norm = <class 'needle.nn.nn_basic.LayerNorm1d'>\n",
      "drop_prob = 0.1\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mResidualBlock\u001b[39;49;00m(dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=\u001b[94m0.1\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:16: NotImplementedError\n",
      "\u001b[31m\u001b[1m______________________ test_mlp_residual_block_forward_1 _______________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_residual_block_forward_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           residual_block_forward(\u001b[94m15\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, nn.LayerNorm1d, \u001b[94m0.5\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.358399\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.384224\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.255451\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.077662\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.939582\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.525591\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.99213\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.012827\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ]\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                dtype=np.float32,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2245: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:382: in residual_block_forward\n",
      "    \u001b[0moutput_tensor = ResidualBlock(dim, hidden_dim, norm, drop_prob)(input_tensor)\u001b[90m\u001b[39;49;00m\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 15, hidden_dim = 10, norm = <class 'needle.nn.nn_basic.LayerNorm1d'>\n",
      "drop_prob = 0.5\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mResidualBlock\u001b[39;49;00m(dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=\u001b[94m0.1\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:16: NotImplementedError\n",
      "\u001b[31m\u001b[1m_________________________ test_mlp_resnet_num_params_1 _________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_resnet_num_params_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           mlp_resnet_num_params(\u001b[94m150\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, nn.LayerNorm1d),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m68360\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2275: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:387: in mlp_resnet_num_params\n",
      "    \u001b[0mmodel = MLPResNet(dim, hidden_dim, num_blocks, num_classes, norm)\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 150, hidden_dim = 100, num_blocks = 5, num_classes = 10\n",
      "norm = <class 'needle.nn.nn_basic.LayerNorm1d'>, drop_prob = 0.1\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mMLPResNet\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        dim,\u001b[90m\u001b[39;49;00m\n",
      "        hidden_dim=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_blocks=\u001b[94m3\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_classes=\u001b[94m10\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        norm=nn.BatchNorm1d,\u001b[90m\u001b[39;49;00m\n",
      "        drop_prob=\u001b[94m0.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:29: NotImplementedError\n",
      "\u001b[31m\u001b[1m_________________________ test_mlp_resnet_num_params_2 _________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_resnet_num_params_2\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           mlp_resnet_num_params(\u001b[94m10\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m, nn.BatchNorm1d),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[94m21650\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2284: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:387: in mlp_resnet_num_params\n",
      "    \u001b[0mmodel = MLPResNet(dim, hidden_dim, num_blocks, num_classes, norm)\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 10, hidden_dim = 100, num_blocks = 1, num_classes = 100\n",
      "norm = <class 'needle.nn.nn_basic.BatchNorm1d'>, drop_prob = 0.1\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mMLPResNet\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        dim,\u001b[90m\u001b[39;49;00m\n",
      "        hidden_dim=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_blocks=\u001b[94m3\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_classes=\u001b[94m10\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        norm=nn.BatchNorm1d,\u001b[90m\u001b[39;49;00m\n",
      "        drop_prob=\u001b[94m0.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:29: NotImplementedError\n",
      "\u001b[31m\u001b[1m__________________________ test_mlp_resnet_forward_1 ___________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_resnet_forward_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           mlp_resnet_forward(\u001b[94m10\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, nn.LayerNorm1d, \u001b[94m0.5\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[94m3.046162\u001b[39;49;00m, \u001b[94m1.44972\u001b[39;49;00m, -\u001b[94m1.921363\u001b[39;49;00m, \u001b[94m0.021816\u001b[39;49;00m, -\u001b[94m0.433953\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[94m3.489114\u001b[39;49;00m, \u001b[94m1.820994\u001b[39;49;00m, -\u001b[94m2.111306\u001b[39;49;00m, \u001b[94m0.226388\u001b[39;49;00m, -\u001b[94m1.029428\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                dtype=np.float32,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2293: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:394: in mlp_resnet_forward\n",
      "    \u001b[0moutput_tensor = MLPResNet(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 10, hidden_dim = 5, num_blocks = 2, num_classes = 5\n",
      "norm = <class 'needle.nn.nn_basic.LayerNorm1d'>, drop_prob = 0.5\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mMLPResNet\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        dim,\u001b[90m\u001b[39;49;00m\n",
      "        hidden_dim=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_blocks=\u001b[94m3\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_classes=\u001b[94m10\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        norm=nn.BatchNorm1d,\u001b[90m\u001b[39;49;00m\n",
      "        drop_prob=\u001b[94m0.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:29: NotImplementedError\n",
      "\u001b[31m\u001b[1m__________________________ test_mlp_resnet_forward_2 ___________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_resnet_forward_2\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           mlp_resnet_forward(\u001b[94m15\u001b[39;49;00m, \u001b[94m25\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m14\u001b[39;49;00m, nn.BatchNorm1d, \u001b[94m0.0\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array(\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.92448235\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m2.745743\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m1.5077105\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.130784\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m1.2078242\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m0.09833566\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m0.69301605\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m2.8945382\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.259397\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.13866742\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m2.963875\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m4.8566914\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m1.7062538\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m4.846424\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                    [\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.6653336\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m2.4708004\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m2.0572243\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m1.0791507\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m4.3489094\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m3.1086435\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m0.0304327\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m1.9227124\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m1.416201\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m7.2151937\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m1.4858506\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94m7.1039696\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m2.1589825\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                        -\u001b[94m0.7593413\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    ],\u001b[90m\u001b[39;49;00m\n",
      "                ],\u001b[90m\u001b[39;49;00m\n",
      "                dtype=np.float32,\u001b[90m\u001b[39;49;00m\n",
      "            ),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m1e-5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2308: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:394: in mlp_resnet_forward\n",
      "    \u001b[0moutput_tensor = MLPResNet(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 15, hidden_dim = 25, num_blocks = 5, num_classes = 14\n",
      "norm = <class 'needle.nn.nn_basic.BatchNorm1d'>, drop_prob = 0.0\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mMLPResNet\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        dim,\u001b[90m\u001b[39;49;00m\n",
      "        hidden_dim=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_blocks=\u001b[94m3\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        num_classes=\u001b[94m10\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        norm=nn.BatchNorm1d,\u001b[90m\u001b[39;49;00m\n",
      "        drop_prob=\u001b[94m0.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:29: NotImplementedError\n",
      "\u001b[31m\u001b[1m____________________________ test_mlp_train_epoch_1 ____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_train_epoch_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           train_epoch_1(\u001b[94m5\u001b[39;49;00m, \u001b[94m250\u001b[39;49;00m, ndl.optim.Adam, lr=\u001b[94m0.01\u001b[39;49;00m, weight_decay=\u001b[94m0.1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array([\u001b[94m0.675267\u001b[39;49;00m, \u001b[94m1.84043\u001b[39;49;00m]),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m0.0001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m0.0001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2353: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:402: in train_epoch_1\n",
      "    \u001b[0mtrain_dataset = ndl.data.MNISTDataset(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.datasets.mnist_dataset.MNISTDataset object at 0x10bf25160>\n",
      "image_filename = './data/train-images-idx3-ubyte.gz'\n",
      "label_filename = './data/train-labels-idx1-ubyte.gz', transforms = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        image_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        label_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        transforms: Optional[List] = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/datasets/mnist_dataset.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[31m\u001b[1m____________________________ test_mlp_eval_epoch_1 _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_eval_epoch_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           eval_epoch_1(\u001b[94m10\u001b[39;49;00m, \u001b[94m150\u001b[39;49;00m), np.array([\u001b[94m0.9164\u001b[39;49;00m, \u001b[94m4.137814\u001b[39;49;00m]), rtol=\u001b[94m1e-5\u001b[39;49;00m, atol=\u001b[94m1e-5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2362: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:415: in eval_epoch_1\n",
      "    \u001b[0mtest_dataset = ndl.data.MNISTDataset(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <needle.data.datasets.mnist_dataset.MNISTDataset object at 0x10bf274a0>\n",
      "image_filename = './data/t10k-images-idx3-ubyte.gz'\n",
      "label_filename = './data/t10k-labels-idx1-ubyte.gz', transforms = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        image_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        label_filename: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        transforms: Optional[List] = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/data/datasets/mnist_dataset.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[31m\u001b[1m____________________________ test_mlp_train_mnist_1 ____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mlp_train_mnist_1\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        np.testing.assert_allclose(\u001b[90m\u001b[39;49;00m\n",
      ">           train_mnist_1(\u001b[94m250\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, ndl.optim.SGD, \u001b[94m0.001\u001b[39;49;00m, \u001b[94m0.01\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "            np.array([\u001b[94m0.4875\u001b[39;49;00m, \u001b[94m1.462595\u001b[39;49;00m, \u001b[94m0.3245\u001b[39;49;00m, \u001b[94m1.049429\u001b[39;49;00m]),\u001b[90m\u001b[39;49;00m\n",
      "            rtol=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            atol=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2368: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:429: in train_mnist_1\n",
      "    \u001b[0mout = train_mnist(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "batch_size = 250, epochs = 2, optimizer = <class 'needle.optim.SGD'>, lr = 0.001\n",
      "weight_decay = 0.01, hidden_dim = 100, data_dir = './data'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtrain_mnist\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        batch_size=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        epochs=\u001b[94m10\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        optimizer=ndl.optim.Adam,\u001b[90m\u001b[39;49;00m\n",
      "        lr=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        weight_decay=\u001b[94m0.001\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        hidden_dim=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        data_dir=\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m4\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:51: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_residual_block_num_params_1\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_residual_block_num_params_2\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_residual_block_forward_1\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_resnet_num_params_1\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_resnet_num_params_2\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_resnet_forward_1\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_resnet_forward_2\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_train_epoch_1\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_eval_epoch_1\u001b[0m - NotImplementedError\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1mtest_mlp_train_mnist_1\u001b[0m - NotImplementedError\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m10 failed\u001b[0m, \u001b[33m83 deselected\u001b[0m\u001b[31m in 0.33s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -v -k \"test_mlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /Users/shreyasridhar/Desktop/DL Systems/hw2\n",
      "plugins: anyio-4.8.0\n",
      "collected 19 items / 18 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw2/test_nn_and_optim.py \n",
      "Submitting mlp_resnet...\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ submit_mlp_resnet _______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_mlp_resnet\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       mugrade.submit(residual_block_num_params(\u001b[94m17\u001b[39;49;00m, \u001b[94m13\u001b[39;49;00m, nn.BatchNorm1d))\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:2376: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/hw2/test_nn_and_optim.py\u001b[0m:375: in residual_block_num_params\n",
      "    \u001b[0mmodel = ResidualBlock(dim, hidden_dim, norm)\u001b[90m\u001b[39;49;00m\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "dim = 17, hidden_dim = 13, norm = <class 'needle.nn.nn_basic.BatchNorm1d'>\n",
      "drop_prob = 0.1\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mResidualBlock\u001b[39;49;00m(dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=\u001b[94m0.1\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/mlp_resnet.py\u001b[0m:16: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw2/test_nn_and_optim.py::\u001b[1msubmit_mlp_resnet\u001b[0m - NotImplementedError\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m18 deselected\u001b[0m\u001b[31m in 0.22s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"qTskW8hPqLZXWgkH0eHH\" \"$HW2_NAME\" -k \"mlp_resnet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encourage you to experiment with the `mlp_resnet.py` training script.\n",
    "You can investigate the effect of using different initializers on the Linear layers,\n",
    "increasing the dropout probability,\n",
    "or adding transforms (via a list to the `transforms=` keyword argument of Dataset)\n",
    "such as random cropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
